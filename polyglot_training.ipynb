{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e430706-b43a-48a0-a907-78f35a203030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263a30d4-e4e6-4e09-bac1-dfedbab8beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "644it [00:01, 362.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-1.3b\", eos_token=\"</s>\")\n",
    "\n",
    "formatted_data = [] \n",
    "for _, row in tqdm(train.iterrows()):\n",
    "    for q_col in [\"질문_1\", \"질문_2\"]:\n",
    "        for a_col in [\"답변_1\", \"답변_2\", \"답변_3\", \"답변_4\", \"답변_5\"]:\n",
    "            # 질문과 답변 쌍을 </s> token으로 연결 \n",
    "            input_text = row[q_col] + tokenizer.eos_token + row[a_col] \n",
    "            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "            formatted_data.append(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e452c2d4-bff2-4dd2-8344-9e4a337b72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/polyglot-ko-1.3b\")\n",
    "model.to(device) \n",
    "\n",
    "model\n",
    "\n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69422f1b-e2af-4089-bd64-339e3d258742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1 - Avg Loss: 1.3771:  28%|██▊       | 1830/6440 [04:47<11:49,  6.50it/s]"
     ]
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"LR\": 2e-5, \n",
    "    \"EPOCHS\": 1, \n",
    "}\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['LR'])\n",
    "model.train()\n",
    "\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(formatted_data), total=len(formatted_data))\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        # 데이터를 GPU단으로 이동\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 진행률 표시줄에 평균 손실 업데이트\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} - Avg Loss: {total_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    # 에폭의 평균 손실을 출력\n",
    "    print(f\"Epoch {epoch+1}/{CFG['EPOCHS']}, Average Loss: {total_loss / len(formatted_data)}\")\n",
    "\n",
    "# 모델 저장\n",
    "model_save_path = \"./hansol-polyglot1.3b.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195159e-16b6-49d4-a5a5-206caacc3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 Fine-tuned 모델과 토크나이저 불러오기\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-1.3b\", eos_token=\"</s>\")\n",
    "\n",
    "# Inference를 위한 test.csv 파일 로드\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# test.csv의 '질문'에 대한 '답변'을 저장할 리스트\n",
    "preds = []\n",
    "\n",
    "# '질문' 컬럼의 각 질문에 대해 답변 생성\n",
    "for test_question in tqdm(test['질문']):\n",
    "    # 입력 텍스트를 토큰화하고 모델 입력 형태로 변환\n",
    "    input_ids = tokenizer.encode(test_question + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # 답변 생성\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=300,\n",
    "        temperature=0.9,\n",
    "        top_k=1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    # 생성된 텍스트(답변) 저장\n",
    "    for generated_sequence in output_sequences:\n",
    "        full_text = tokenizer.decode(generated_sequence, skip_special_tokens=False)\n",
    "        # 질문과 답변의 사이를 나타내는 eos_token (</s>)를 찾아, 이후부터 출력\n",
    "        answer_start = full_text.find(tokenizer.eos_token) + len(tokenizer.eos_token)\n",
    "        answer_only = full_text[answer_start:].strip()\n",
    "        answer_only = answer_only.replace('\\n', ' ')\n",
    "        preds.append(answer_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36e0a5-fa73-4f2d-9b17-a77ded2b7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f41aff-1aa7-4b1a-9f09-908f44c09870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "# 평가를 위한 Embedding Vector 추출에 활용하는 모델은 'distiluse-base-multilingual-cased-v1' 이므로 반드시 확인해주세요.\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 생성한 모든 응답(답변)으로부터 Embedding Vector 추출\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "# 제출 양식 파일(sample_submission.csv)을 활용하여 Embedding Vector로 변환한 결과를 삽입\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()\n",
    "# 리더보드 제출을 위한 csv파일 생성\n",
    "submit.to_csv('./polyglot1.3b_baseline_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda286e-a7a5-4f65-ad3e-eeb14a60634f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34518b-1ea8-433d-970c-081e28b801da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
